{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb06b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f740665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and scaled successfully.\n",
      "Feature shape: (300, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_29664\\3102510909.py:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  df = pd.read_csv('E:\\AIML Tasks\\city_lifestyle_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "# Assumes the file is in the local directory\n",
    "df = pd.read_csv('E:\\AIML Tasks\\city_lifestyle_dataset.csv')\n",
    "\n",
    "# 2. Feature Selection\n",
    "# We drop categorical columns ('city_name', 'country') for the clustering model\n",
    "# We will keep the original df to map labels back later\n",
    "features = [\n",
    "    'population_density', 'avg_income', 'internet_penetration', \n",
    "    'avg_rent', 'air_quality_index', 'public_transport_score', \n",
    "    'happiness_score', 'green_space_ratio'\n",
    "] # Features derived from dataset [cite: 1]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# 3. Preprocessing: Standardization\n",
    "# Scaling is crucial for K-Means to treat all features equally\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to dataframe for easier handling later (optional)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "print(\"Data loaded and scaled successfully.\")\n",
    "print(f\"Feature shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2dbb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Inertia for K=1 to K=10\n",
    "inertia = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Visualize the Elbow Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertia, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method to Determine Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (WCSS)')\n",
    "plt.grid(True)\n",
    "plt.savefig('elbow_curve.png') \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c991a7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score for K=3: 0.356\n"
     ]
    }
   ],
   "source": [
    "# 1. Fit the Final Model\n",
    "optimal_k = 3  # Adjust based on the Elbow plot results\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 2. Add labels back to original data\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# 3. Evaluate with Silhouette Score\n",
    "# Score ranges from -1 to 1. Higher is better.\n",
    "sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "print(f\"Silhouette Score for K={optimal_k}: {sil_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107b1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dimensionality Reduction (PCA) for Visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 2. Create a visualization DataFrame\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['Cluster'] = cluster_labels\n",
    "\n",
    "# 3. Plot the Clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='Cluster', \n",
    "    data=pca_df, \n",
    "    palette='viridis', \n",
    "    s=100, \n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title('City Lifestyle Clusters (Visualized via PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.savefig('pca_clusters.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a610b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Profiling (Average Values per Group):\n",
      "         population_density   avg_income  internet_penetration     avg_rent  \\\n",
      "Cluster                                                                       \n",
      "0               2991.329412  1434.000000             55.301176   495.411765   \n",
      "1               2367.335664  3804.055944             86.260140  1361.538462   \n",
      "2               8203.625000  2531.805556             72.997222   889.166667   \n",
      "\n",
      "         air_quality_index  public_transport_score  happiness_score  \\\n",
      "Cluster                                                               \n",
      "0                78.517647               40.991765         4.965882   \n",
      "1                53.762238               60.756643         8.153846   \n",
      "2                97.388889               63.093056         5.626389   \n",
      "\n",
      "         green_space_ratio  \n",
      "Cluster                     \n",
      "0                36.027059  \n",
      "1                37.082517  \n",
      "2                25.456944  \n"
     ]
    }
   ],
   "source": [
    "# Analyze the mean values of features for each cluster\n",
    "cluster_summary = df.groupby('Cluster')[features].mean()\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nCluster Profiling (Average Values per Group):\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Visualizing the profile differences (Heatmap)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_summary.T, annot=True, cmap='coolwarm', fmt='.1f')\n",
    "plt.title('Feature Distribution by Cluster')\n",
    "plt.savefig('cluster_heatmap.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93434d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
